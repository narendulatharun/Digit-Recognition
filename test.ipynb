{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "E4qQ5gw-IhWQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from tensorflow.python.client import device_lib\n",
        "# device_lib.list_local_devices()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TcgWHE3E3PBK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "#download mnist data and split into train and testing data sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vMud3fk33zoT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "e22f439e-a8e3-4891-9541-04dd430293c2"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#plot the first image in the dataset\n",
        "plt.imshow(x_test[500])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7a495f0fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "df9Llw-m4S_T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "397a22af-e51f-4a69-f98b-ee1089debf83"
      },
      "cell_type": "code",
      "source": [
        "#shape of the image\n",
        "x_train[0].shape\n",
        "# 28 * 28 pixels i.e., 784"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "sALTVfqw4el5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Data pre-processing\n",
        "x_train = x_train.reshape(60000, 28, 28, 1)\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)\n",
        "# The last number is 1, which signifies that the images are greyscale."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PEh8uTjc47V9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "85b3cbcf-25a0-41e4-bbb4-a294648ec8ea"
      },
      "cell_type": "code",
      "source": [
        "# We need to ‘one-hot-encode’ our target variable. This means that a column will be created for each output category and a binary variable is inputted for each category. For example, we saw that the first image in the dataset is a 5. This means that the sixth number in our array will have a 1 and the rest of the array will be filled with 0.\n",
        "from keras.utils import to_categorical\n",
        "#one-hot encode target column\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "y_train[0]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "ntkJCBP45eTo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Building the Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten\n",
        "\n",
        "#Create a Model\n",
        "model = Sequential()\n",
        "# The model type that we will be using is Sequential.\n",
        "# Sequential is the easiest way to build a model in Keras.\n",
        "# It allows you to build a model layer by layer\n",
        "\n",
        "#add Model Layers\n",
        "# ‘add()’ function to add layers to our model.\n",
        "# Our first 2 layers are Conv2D layers. \n",
        "# These are convolution layers that will deal with our input images, \n",
        "# which are seen as 2-dimensional matrices.\n",
        "# Kernel size is the size of the filter matrix for our convolution. \n",
        "# So a kernel size of 3 means we will have a 3x3 filter matrix.\n",
        "model.add(Conv2D(64, kernel_size=3, activation = 'relu',\n",
        "                 input_shape=(28,28,1)))\n",
        "''' model.add(Conv2D(64, kernel_size=3, activation = 'relu',\n",
        "                 input_shape=(28,28,1)))\n",
        "# Our first layer also takes in an input shape. \n",
        "# This is the shape of each input image, \n",
        "# 28,28,1 as seen earlier on, with the 1 signifying that the images \n",
        "# are greyscale.\n",
        "# In between the Conv2D layers and the dense layer, there is a ‘Flatten’ layer. \n",
        "# Flatten serves as a connection between the convolution and dense layers.\n",
        "model.add(Conv2D(64, kernel_size=3, activation = 'relu',\n",
        "                 input_shape=(28,28,1)))\n",
        "model.add(Conv2D(64, kernel_size=3, activation = 'relu',\n",
        "                 input_shape=(28,28,1)))\n",
        "model.add(Conv2D(64, kernel_size=3, activation = 'relu',\n",
        "                 input_shape=(28,28,1)))\n",
        "model.add(Conv2D(64, kernel_size=3, activation = 'relu',\n",
        "                 input_shape=(28,28,1)))\n",
        "# ‘Dense’ is the layer type we will use in for our output layer. \n",
        "# Dense is a standard layer type that is used in many cases for neural networks.\n",
        "model.add(Conv2D(64, kernel_size=3, activation = 'relu',\n",
        "                 input_shape=(28,28,1)))\n",
        "model.add(Conv2D(64, kernel_size=3, activation = 'relu',\n",
        "                 input_shape=(28,28,1)))\n",
        "model.add(Conv2D(64, kernel_size=3, activation = 'relu',\n",
        "                 input_shape=(28,28,1)))'''\n",
        "model.add(Conv2D(32, kernel_size=3, activation = 'relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "# The activation is ‘softmax’. Softmax makes the output sum up to 1 \n",
        "# so the output can be interpreted as probabilities. \n",
        "# The model will then make its prediction based on which option \n",
        "# has the highest probability.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rt06yzLIZPH5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compiling the Model\n",
        "# Compiling the model takes three parameters: \n",
        "# optimizer, loss and metrics.\n",
        "# Compile model using accuracy to measure model perfomance\n",
        "model.compile(optimizer = 'adam', loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AugiVzbNZbHw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The optimizer controls the learning rate. We will be using ‘adam’ as our optmizer. Adam is generally a good optimizer to use for many cases. The adam optimizer adjusts the learning rate throughout training.\n",
        "\n",
        "The learning rate determines how fast the optimal weights for the model are calculated. A smaller learning rate may lead to more accurate weights (up to a certain point), but the time it takes to compute the weights will be longer.\n",
        "\n",
        "We will use ‘categorical_crossentropy’ for our loss function. This is the most common choice for classification. A lower score indicates that the model is performing better.\n",
        "\n",
        "To make things even easier to interpret, we will use the ‘accuracy’ metric to see the accuracy score on the validation set when we train the model.*italicized text*"
      ]
    },
    {
      "metadata": {
        "id": "TZXJRwIOZj6h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "outputId": "bc86a656-511a-4c21-9a0a-9bf75124eb74"
      },
      "cell_type": "code",
      "source": [
        "#Training the model\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=20)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 22s 373us/step - loss: 11.9329 - acc: 0.2593 - val_loss: 11.8364 - val_acc: 0.2656\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 11.5964 - acc: 0.2805 - val_loss: 11.2940 - val_acc: 0.2993\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 16s 259us/step - loss: 11.7176 - acc: 0.2730 - val_loss: 11.3794 - val_acc: 0.2940\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 11.4081 - acc: 0.2922 - val_loss: 11.3794 - val_acc: 0.2940\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 16s 262us/step - loss: 11.4081 - acc: 0.2922 - val_loss: 11.3794 - val_acc: 0.2940\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 16s 267us/step - loss: 11.4081 - acc: 0.2922 - val_loss: 11.3794 - val_acc: 0.2940\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 11.4081 - acc: 0.2922 - val_loss: 11.3794 - val_acc: 0.2940\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 16s 262us/step - loss: 11.4081 - acc: 0.2922 - val_loss: 11.3794 - val_acc: 0.2940\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 16s 273us/step - loss: 11.4081 - acc: 0.2922 - val_loss: 11.3794 - val_acc: 0.2940\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 16s 273us/step - loss: 11.4081 - acc: 0.2922 - val_loss: 11.3794 - val_acc: 0.2940\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 16s 264us/step - loss: 11.4081 - acc: 0.2922 - val_loss: 11.3794 - val_acc: 0.2940\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 16s 265us/step - loss: 11.4081 - acc: 0.2922 - val_loss: 11.3794 - val_acc: 0.2940\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 16s 266us/step - loss: 11.4081 - acc: 0.2922 - val_loss: 11.3794 - val_acc: 0.2940\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 16s 268us/step - loss: 11.4081 - acc: 0.2922 - val_loss: 11.3794 - val_acc: 0.2940\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 16s 270us/step - loss: 11.4081 - acc: 0.2922 - val_loss: 11.3794 - val_acc: 0.2940\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 11.4081 - acc: 0.2922 - val_loss: 11.3794 - val_acc: 0.2940\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 11.4081 - acc: 0.2922 - val_loss: 11.3794 - val_acc: 0.2940\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 11.4081 - acc: 0.2922 - val_loss: 11.3794 - val_acc: 0.2940\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 16s 273us/step - loss: 11.4081 - acc: 0.2922 - val_loss: 11.3794 - val_acc: 0.2940\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 17s 280us/step - loss: 11.4081 - acc: 0.2922 - val_loss: 11.3794 - val_acc: 0.2940\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7a494f6a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "nGqFcqI-Z9o9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we will train our model. To train, we will use the ‘fit()’ function on our model with the following parameters: training data (train_X), target data (train_y), validation data, and the number of epochs.\n",
        "\n",
        "For our validation data, we will use the test set provided to us in our dataset, which we have split into X_test and y_test.\n",
        "\n",
        "The number of epochs is the number of times the model will cycle through the data. The more epochs we run, the more the model will improve, up to a certain point. After that point, the model will stop improving during each epoch. For our model, we will set the number of epochs to 3."
      ]
    },
    {
      "metadata": {
        "id": "rBL7BRJRaBFX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "e1273a2e-5674-4b35-c616-4acaf5b2486a"
      },
      "cell_type": "code",
      "source": [
        "model.predict(x_test[:5])\n",
        "# x_test[:5]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "1rAofNpmfKnJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "639542bd-91dc-4e6d-a543-ec4ef18ae358"
      },
      "cell_type": "code",
      "source": [
        "y_test[:5]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    }
  ]
}